%% LyX 2.3.4.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english,format=acmsmall]{article}
\usepackage{newcent}
\usepackage[scaled=0.85]{beramono}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm,headheight=2.5cm,headsep=2.5cm,footskip=1cm}
\usepackage{babel}
\usepackage{array}
\usepackage{url}
\usepackage{amstext}
\usepackage{rotating}
\usepackage{xargs}[2008/03/08]
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\newcommand*\LyXZeroWidthSpace{\hspace{0pt}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
% recommended but missing
%\usepackage{orcidlink}
%\usepackage{thumbpdf}


 
\usepackage{amssymb} % Provides \checkmark

\makeatother

\usepackage{listings}
\lstset{basicstyle={\ttfamily\small},
breaklines=false,
columns=flexible,
keepspaces=true,
moredelim={**[is][\bfseries]{~}{~}}}
\renewcommand{\lstlistingname}{Listing}

\begin{document}
\title{User's Guide for UltimateKalman:\\
a Library for Flexible Kalman Filtering and Smoothing Using Orthogonal
Transformations}
\author{Sivan Toledo}

\maketitle
\global\long\def\linearestimator{F}%

\global\long\def\modelfun{M}%

\global\long\def\penaltyfun{\phi}%

\global\long\def\objectivefun{\phi}%

\global\long\def\grad{\nabla}%

\newcommandx\hessian[1][usedefault, addprefix=\global, 1=]{\nabla_{#1}^{2}}%

\global\long\def\jacobian{\mathrm{J}}%

\global\long\def\exact#1{#1}%

\global\long\def\estimate#1{\hat{#1}}%

\global\long\def\controlpoint{\rho}%

\global\long\def\location{\ell}%

\global\long\def\noise{\epsilon}%

\global\long\def\observations{b}%

\global\long\def\expectation{\operatorname{E}}%

\global\long\def\iu{\mathbf{i}}%

\global\long\def\vecone{\mathbf{1}}%

\global\long\def\veczero{\mathbf{0}}%

\global\long\def\covold{\text{cov}}%

\global\long\def\nonjsscov{\operatorname{cov}}%

\global\long\def\cov{\operatorname{cov}}%

\global\long\def\var{\text{var}}%

\global\long\def\fim{\mathcal{I}}%

\global\long\def\loglikelihood{\mathcal{L}}%

\global\long\def\score{\mathcal{S}}%

\global\long\def\duration{\vartheta}%

\global\long\def\attenuation{a}%
\global\long\def\cmplxatt{\alpha}%

\global\long\def\initialphase{\varphi}%

\global\long\def\satclockerr{\eta}%

\global\long\def\ionodelay{\psi}%

\global\long\def\tropodelay{\xi}%

\global\long\def\xcorr{\operatorname{xcorr}}%

\global\long\def\diag{\operatorname{diag}}%

\global\long\def\rank{\operatorname{rank}}%

\global\long\def\erf{\operatorname{erf}}%

\global\long\def\erfc{\operatorname{erfc}}%

\global\long\def\range{\operatorname{range}}%

\global\long\def\trace{\operatorname{trace}}%

\global\long\def\ops{\operatorname{ops}}%

\global\long\def\prob{\operatorname{Prob}}%

\global\long\def\real{\text{Re}}%

\global\long\def\imag{\text{Im}}%

\global\long\def\square{\text{\ensuremath{\blacksquare}}}%

\global\long\def\irange{\boldsymbol{:}}%

UltimateKalman is a library that implements efficient and flexible
Kalman filtering and smoothing algorithms. The library contains MATLAB,
C, and Java implementations (currently, the Java implementations
does not contain all the algorithms). The library is available on
GitHub at \url{https://github.com/sivantoledo/ultimate-kalman}. The
release history of the library is as follows:
\begin{itemize}
\item \textbf{Release 1.2.0} contains the sequential UltimateKalman algorithm,
which is documented carefully in an article in the ACM Transactions
on Mathematical Software~\cite{doi:10.1145/3699958}. The algorithm
is a slight extension an algorithm by Paige and Saunders~\cite{PaigeSaunders:1977:Kalman},
which to the best of our knowledge, has not been implemented before.
The algorithm uses orthogonal transformations so it has good numerical
stability. The algorithm is implemented monolithically in all 3 languages.
Please cite this article when citing the sequential UltimateKalman
algorithm or its implementation. To use that version, please use the
user guide from that release, not this document.
\item \textbf{Release 2.0.0} contains three additional algorithms in MATLAB
and C, including two parallel-in-time smoothers, the Odd-Even smoother
proposed in an article by Gargir and Toledo~\cite{toappear:IPDPS2025}
and the smoother proposed by Särkkä and García-Fernández~. The code
in this release was used to perform the experiments reported by Gargir
and Toledo~\cite{toappear:IPDPS2025}; the release is meant mostly
to document these experiments, not for adoption by users.
\item \textbf{Release 2.1.0} is a significantly cleaned up version of the
codes described by Gargir and Toledo~\cite{toappear:IPDPS2025}.
It is meant to be adopted by users. This is the version described
in this guide.\\
The C codes in this release use the same API as the implementation
in Release~1.2.0, but the code has been split into multiple files
so the build is more complicated. The MATLAB also retains the same
API, but class names have changed. The Java implementation is identical
to the implementation in Release~1.2.0.
\end{itemize}
The implementation in each language is separate and does not rely
on the others. The implementation includes MATLAB adapter classes
that allow invocation of the C and Java implementations from MATLAB.
This allows a single set of MATLABexample functions to invoke all
three implementations. 

The programming interfaces of all three implementations are similar.
They offer exactly the same functionality using the same abstractions,
and each employs good programming practices of the respected language.
For example, the MATLAB and Java implementations use overloading
(using the same method name more than once, with different argument
lists). Another example is a method that returns two values in the
MATLAB implementation, but only one in the others; the second value
is returned by a separate method or function in the Java and C implementations.
The only differences are ones that are unavoidable due to the constraints
of each programming language.

The MATLAB implementation does not rely on any MATLAB toolbox, only
on functionality that is part of the core product. The implementation
also works under GNU Octave. The C implementation relies on basic
matrix and vector operations from the BLAS~\cite{BLAS,BLAS3ALG}
and on the QR and Cholesky factorizations from LAPACK~\cite{LAPACK-UG}.
The C implementation of the parallel-in-time smoothers used the Threading
Building Blocks (TBB) library to express shared-memory parallelism.
TBB is a C++ library and the code uses a single C++ source file
to expose the parallel primitives. The code can also be compiled without
TBB, but this generates a sequential algorithm, not a multi-threaded
(multi-core) one. The Java implementation uses the Apache Commons
Math library for both basic matrix-vector operations and for the QR
and Cholesky factorizations. The Cholesky factorization is used only
to factor covariance matrices that are specified explicitly, as opposed
to being specified by inverse factors or triangular factors.

We first describe how the different implementations represent matrices,
vectors, and covariance matrices. Then we describe in detail the MATLAB
programming interface and implementation and then comment on the differences
between them and those of the other two implementations. The guide
ends with a discussion of the data structures that are used to represent
the step sequence and a presentation of a mechanism for measuring
the performance of the implementations.

The code has been tested with MATLAB R2021b (version 9.11) and R2024a,
and with GNU OCTAVE 7.1.0, both running under Windows 11. The code
has also been tested on Linux and on MacOS. Under Windows, MATLAB
was configured to use Microsoft Visual C/C++ 2019 to compile C (mex)
code. OCTAVE was configured to use mingw64 to compile C (mex) code.
The code also compiles as a standalone C program under both GCC
and Microsoft Visual C/C++ 2022, as well as under Java version 1.8
(also called version 8) and up.

The distribution archive contains a number of directories with scripts
that build libraries, programs, and this document. The scripts for
Windows are called \texttt{build.bat}. To run them, type \texttt{build}
on the Windows command prompt. The scripts for Linux and MacOS are
called \texttt{build.sh}. To run them, type \texttt{./build.sh} in
a shell (terminal window). The \texttt{build.sh} files must have permissions
that allows them to execute as scripts; unpacking the distribution
archive normally gives them this permission, but if you receive a
\texttt{permission denied} error message, give the file this premission
using the command \texttt{chmod +x build.sh} and try again.

The rest of this guild is organized as follows. Section~\ref{sec:matrices-and-vectors}
explains how vectors and matrices are represented in the three implementations.
Section~\ref{sec:covariance-matrices} explains how covariance matrices
are represented. Section~\ref{sec:matlab} presents the programming
interface of the MATLAB implementation and how to add it to MATLAB's
search path.

\section{\label{sec:matrices-and-vectors}The representation of vectors and
matrices}

The MATLAB implementation uses native MATLAB matrices and vectors.
The Java implementation uses the types \texttt{RealMatrix} and \texttt{RealVector}
from the Apache Commons Math library~(both are interface types with
multiple implementations). 

The C implementation defines a type called \texttt{matrix\_t} to
represent matrices and vectors. The implementation defines functions
that implement basic operations of matrices and vectors of this type.
The type is implemented using a structure that contains a pointer
to an array of double-precision elements, which are stored columnwise
as in the BLAS and LAPACK, and integers that describe the number
of rows and columns in the matrix and the stride along rows (the so-called
leading dimension in the BLAS and LAPACK interfaces). To avoid name-space
pollution, in client code this type is called \texttt{kalman\_matrix\_t}.

State vectors are not always observable. This topic is explained in
Section ~3.2 in the companion article. This situation usually arises
when there are not enough observations to estimate the state. The
function calls and methods that return estimates of state vectors
and the covariance matrices of the estimates return in such cases
a vector of \texttt{NaN}s (not-a-number, a floating point value that
indicates that the value is not available) and a diagonal matrix whose
diagonal elements are \texttt{NaN}.

\section{\label{sec:covariance-matrices}The representation of covariance
matrices}

Like all Kalman filters, UltimateKalman consumes covariance matrices
that describe the distribution of the error terms and produces covariance
matrices that describe the uncertainty in the state estimates $\estimate u_{i}$.
The input covariance matrices are not used explicitly; instead, the
inverse factor $W$ of a covariance matrix $C=(W^{T}W)^{-1}$ is multiplied,
not necessarily explicitly, by matrices or by a vector. 

Therefore, the programming interface of UltimateKalman expects input
covariance matrices to be represented as objects belonging to a type
with a method \texttt{weigh} that multiplies the factor $W$ by a
matrix $A$ or a vector $v$. In the MATLAB and Java implementations,
this type is called \texttt{CovarianceMatrix}. The constructors of
these classes accept many representations of a covariance matrix:
\begin{itemize}
\item An explicit covariance matrix $C$; the constructor computes an upper
triangular Cholesky factor $U$ of $C=U^{T}U$ and implements \texttt{X=C.weigh(A)}
by solving $UX=A$.
\item An inverse factor $W$ such that $W^{T}W=C^{-1}$; this factor is
stored and multiplied by the argument of \texttt{weigh}.
\item An inverse covariance matrix $C^{-1}$; the constructor computes its
Cholesky factorization and stores the lower-triangular factor as $W$.
\item A diagonal covariance matrix represented by a vector $w$ such that
$W=\text{diag}(w)$ (the elements of $w$ are inverses of standard
deviations).
\item A few other, less important, variants.
\end{itemize}
In the MATLAB implementation, the way that the argument to the constructor
represents $C$ is defined by a single-character argument (with values
\texttt{C}, \texttt{W}, \texttt{I}, and \texttt{w}, respectively).
In the Java implementation, \texttt{CovarianceMatrix} is an interface
with two implementing classes, \texttt{DiagonalCovarianceMatrix} and
\texttt{RealCovarianceMatrix}; the way that the numeric argument represents
$C$ is specified using \texttt{enum} constants defined in the implementation
classes:
\begin{lstlisting}
RealCovarianceMatrix.Representation.COVARIANCE_MATRIX
RealCovarianceMatrix.Representation.FACTOR
RealCovarianceMatrix.Representation.INVERSE_FACTOR
DiagonalCovarianceMatrix.Representation.COVARIANCE_MATRIX
DiagonalCovarianceMatrix.Representation.DIAGONAL_VARIANCES
DiagonalCovarianceMatrix.Representation.DIAGONAL_STANDARD_DEVIATIONS
DiagonalCovarianceMatrix.Representation.DIAGONAL_INVERSE_STANDARD_DEVIATIONS
\end{lstlisting}
The \texttt{RealCovarianceMatrix} class has a single constructor that
takes a \texttt{RealMatrix} and a representation constant. The \texttt{DiagonalCovarianceMatrix}
class several constructors that take either a \texttt{RealVector},
an array of \texttt{double} values, or a single \texttt{double} and
a dimension (the covariance matrix is then a scaled identity); all
also take as a second argument a representation constant.

Covariance input matrices are passed to the C implementation in a
similar manner, but without a class; each input covariance matrix
is represented using two arguments, a matrix and a single character
(\texttt{C}, \texttt{W}, \texttt{I}, or \texttt{w}) that defines how
the given matrix is related to $C$. 

The UltimateKalman algorithm always returns the covariance matrix
of $\estimate u_{i}$ as an upper triangular inverse factor $W$.
The other algorithms return an explicit covariance matrix $C$. The
MATLAB and Java implementations return covariance matrices as objects
of the \texttt{CovarianceMatrix} type (always with an inverse-factor
representation); the C implementation includes one function that returns
the type of the covariance matrix (a single character) and another
that returns the factor $W$ or the explicit matrix $C$.

\section{\label{sec:matlab}The MATLAB programming interface}

The MATLAB implementation resides in the \texttt{matlab} directory
of the distribution archive. To be able to use it, you must add this
directory to your MATLAB search path using MATLAB's \texttt{addpath}
command. 

The MATLAB implementation is object oriented and is implemented as
a collection of handle (reference) classes called \texttt{KalmanUltimate},
\texttt{KalmanConventional}, \texttt{KalmanOddevenSmoother}, \texttt{KalmanAssociativeSmoother},
and \texttt{KalmanSparse}. The first four classes implement, respectively,
the UltimateKalman algorithm~\cite{doi:10.1145/3699958,PaigeSaunders:1977:Kalman},
a conventional Kalman filter~\cite{Kalman:1960:KalmanFilter} and
RTS smoother~, the Gargir-Toledo parallel smoother~\cite{toappear:IPDPS2025},
and the parallel smoother by Särkkä and García-Fernández~. The fifth
implementation, \texttt{KalmanSparse}, uses an explicit sparse QR
factorizations to filter and smooth; it is inefficient, especially
when filtering, and is meant only for testing the correctness of other
implementations. It is particularly simple and therefore it is particularly
easy to ensure that it is correct. The interface of all these classes
is exactly the same. The constructor takes one optional argument,
a structure that specifies algorithmic options.

\begin{lstlisting}
kalman = KalmanUltimate(options)
\end{lstlisting}
or

\begin{lstlisting}
kalman = KalmanUltimate()
\end{lstlisting}

The (overloaded) methods that advance the filter through a sequence
of steps are \texttt{evolve} and \texttt{observe}. Each of them must
be called exactly once at each step, in this order. The \texttt{evolve}
method declares the dimension of the state of the next step and provides
all the known quantities of the evolution equation, 

\begin{lstlisting}
kalman.evolve(n_i, H_i, F_i, c_i, K_i)
\end{lstlisting}
where \texttt{n\_i} is an integer, the dimension of the state, \texttt{H\_i}
and \texttt{F\_i} are matrices, \texttt{c\_i} is a vector, and \texttt{K\_i}
is a \texttt{CovarianceMatrix} object. The number of rows in\texttt{
H\_i}, \texttt{F\_i}, and \texttt{c\_i} must be the same and must
be equal to the order of \texttt{K\_i}; this is the number $\ell_{i}$
of scalar evolution equations. The number of columns in \texttt{H\_i}
must be \texttt{n\_i} and the number of columns in \texttt{F\_i} must
be equal to the dimension of the previous step. A simplified overloaded
version defines \texttt{H\_i} internally as an $n_{i}$-by-$n_{i-1}$
identity matrix, possibly padded with zero columns

\begin{lstlisting}
kalman.evolve(n_i, F_i, c_i, K_i)
\end{lstlisting}
If $n_{i}>\ell_{i}$, this overloaded version adds the new parameters
to the end of the state vector.

If $n_{i}<\ell_{i}$, the first version must be used; this forces
the user to specify how parameters in $u_{i-1}$ are mapped to the
parameters in $u_{i}$. The \texttt{evolve} method must be called
even in the first step; this design decision was taken mostly to keep
the implementation of all the steps in client code uniform. In the
first step, there is no evolution equation, so the user can pass empty
matrices to the method, or call another simplified overloaded version:

\begin{lstlisting}
kalman.evolve(n_i)
\end{lstlisting}

The \texttt{observe} method comes in two overloaded versions. One
of them must be called to complete the definition of a step. The first
version describes the observation equation and the second tells UltimateKalman
that there are no observations of this step.

\begin{lstlisting}
kalman.observe(G_i, o_i, C_i)
kalman.observe()
\end{lstlisting}

Steps are named using zero-based integer indices; the first step that
is defined is step~$i=0$, the next is step~$1$, and so on. The
\texttt{estimate} methods return the estimate of the state at step
\texttt{i} and optionally the covariance matrix of that estimate,
or the estimate and covariance of the latest step that is still in
memory (normally the last step that was observed):

\begin{lstlisting}
[estimate, covariance] = kalman.estimate(i)
[estimate, covariance] = kalman.estimate()
\end{lstlisting}
If a step is not observable, \texttt{estimate} returns a vector of
$n_{i}$ \texttt{NaN}s (not-a-number, an IEEE-754 floating point representation
of an unknown quantity). 

The \texttt{forget} methods delete from memory the representation
of all the steps up to and including $i$, or all the steps except
for the latest one that is still in memory.

\begin{lstlisting}
kalman.forget(i)
kalman.forget()
\end{lstlisting}
The \texttt{rollback} methods return the filter to its state just
after the invocation of \texttt{evolve} in step \texttt{i}, or just
after the invocation of \texttt{evolve} in the latest step still in
memory.

\begin{lstlisting}
kalman.rollback(i)
kalman.rollback()
\end{lstlisting}
The methods \texttt{earliest} and \texttt{latest} are queries that
take no arguments and return the indices of the earliest and latest
steps that are still in memory.

The \texttt{smooth} method, which also takes no arguments, computes
the smoothed estimates of all the states still in memory, along with
their covariance matrices. After this method is called, \texttt{estimate}
returns the smoothed estimates. A single step can be smoothed many
times; each smoothed estimate will use the information from all past
steps and the information from future steps that are in memory when
\texttt{smooth} is called.

To use the C or Java implementations from within MATLAB, create
an object of one of the adapter classes:
\begin{lstlisting}
kalman = KalmanNative(options)
kalman = KalmanJava(options)
\end{lstlisting}
These adapter classes have exactly the same interface as the MATLAB
implementations (including the fact that the \texttt{options} argument
is optional).

To use the C implementation, you will first need to compile the C
code into a MATLAB-callable dynamically-linked library that MATLAB
uses through an interface called the \texttt{mex} interface. To perform
this step, run the \texttt{UltimateKalman\_build\_\LyXZeroWidthSpace mex.m}
script in the \texttt{matlab} directory. To use the Java implementation,
build the Java library using the instructions in Section~\ref{sec:java},
and add both the resulting library (a \texttt{jar} file) and the library
containing the Apache Commons Math library to MATLAB's Java search
path using MATLAB \texttt{javaaddpath} command. The function \texttt{replication.m}
in the \texttt{examples} sub-directory adds these libraries to the
path and can serve as an example.

\subsection{Options}

The MATLAB implementations interpret a number of options, specified
as fields of the \texttt{options} structure. Most of the implementations
process only a subset of the options (some process none), as shown
in Table~\ref{tab:matlab-options}.
\begin{table}
\begin{tabular}{ll>{\raggedright}p{0.2\textwidth}ccccccc}
field name & type & values (default is 1st) & \begin{turn}{90}
\texttt{KalmanUltimate}
\end{turn} & \begin{turn}{90}
\texttt{KalmanConventional}
\end{turn} & \begin{turn}{90}
\texttt{KalmanOddevenSmoother}
\end{turn} & \begin{turn}{90}
\texttt{KalmanAssociativeSmoother}
\end{turn} & \begin{turn}{90}
\texttt{KalmanSparse}
\end{turn} & \begin{turn}{90}
\texttt{KalmanNative}
\end{turn} & \begin{turn}{90}
\texttt{KalmanJava}
\end{turn}\tabularnewline
\hline 
\texttt{estimateCovariance} & boolean & \texttt{true, false} & $\checkmark$ &  & $\checkmark$ &  &  &  & \tabularnewline
\texttt{covarianceEstimates} & string & \texttt{'PaigeSaunders', 'SelInv'} & $\checkmark$ &  &  &  &  &  & \tabularnewline
\texttt{smoothOnly} & boolean & \texttt{false, true} &  &  &  &  & $\checkmark$ &  & \tabularnewline
\texttt{algorithm} & string & \texttt{'Ultimate', 'Conventional', 'Oddeven', 'Associative'} &  &  &  &  &  & $\checkmark$ & \tabularnewline
\end{tabular}

\caption{\label{tab:matlab-options}Options that affect the behavior of the
MATLAB implementations.}

\end{table}

The meaning of the options is as follows:
\begin{itemize}
\item The \texttt{estimateCovariance} field tells some of the algorithms
that the covariance matrices of the state estimates are not required.
Not computing them saves time in these algorithms. This is particularly
useful in smoothers that are used as a building block of a non-linear
smoother~.
\item The \texttt{covarianceEstimates} field specifies which method to use
to compute the covariance matrices of the state estimates, when more
than one method is available. 
\item The \texttt{smoothOnly} field tells an implementation that filtered
estimates are not required, only smoothed estimates. This can save
time in some implementations (most notably, the \texttt{KalmanSparse}
one).
\item The \texttt{algorithm} field tells the interface to the C implementations
which algorithm to use.
\end{itemize}

\subsection{Implementation Details}

All the implementations extend an abstract class called \texttt{KalmanBase},
which implements most of the methods that handle modifications of
the sequence of steps (forgetting, rolling back, etc.). The \texttt{KalmanOddevenSmoother}
and the \texttt{KalmanAssociativeSmoother} implementations do not
return filtered estimated, only smoothed estimates. They both extend
a second abstract class, \texttt{KalmanExplicitRepresentation}, in
which the \texttt{evolve} and \texttt{observe} methods simply record
the equations for later processing by the smoother. Both of these
implementations are sequential but they exhibit the parallel algorithms
in a clear way that is hopefully easy to implement in parallel programming
environments.

\section{\label{sec:java}The Java programming interface}

The programming interface to the Java implementation is nearly identical.
The implementing class is \texttt{sivantoledo\LyXZeroWidthSpace .kalman\LyXZeroWidthSpace .UltimateKalman}.
It also uses overloaded methods to express default values. It differs
from the MATLAB interface only in that the \texttt{estimate} methods
return only one value, the state estimate. To obtain the matching
covariance matrix, client code must call a separate method, \texttt{covariance}.

\subsection*{Building and Running the Java Code}

The Java implementation resides under the \texttt{java} directory
of the distribution archive. The sources are in the \texttt{src} subdirectory.
To use it, you first need to compile the source code and to assemble
the compiled code into a library (a \texttt{jar} file). The scripts
\texttt{build.bat} and \texttt{build.sh}, both in the \texttt{java}
directory, perform these steps under Windows (\texttt{build.bat})
and Linux and MacOS (\texttt{build.sh}). To run the scripts, your
computer must have a Java development kit (JDK) installed. We used
successfully releases of OpenJDK on both Windows and Linux. The code
is compiled so that the library can be used with any version of Java
starting with version~8 (sometimes also referred to as 1.8).

The build scripts also compile and run an example program, \texttt{Rotation.java}.
It performs the same computations as the MATLAB example function
\texttt{rotation.m} when executed with arguments \texttt{rotation(UltimateKalman,5,2)}.
This program serves as an example that shows how to write Java code
that calls UltimateKalman.

\section{\label{sec:c-lang}The C programming interface}

In the C interface, defined in \texttt{kalman.h}, the filter is represented
by a pointer to a structure of the \texttt{kalman\_t} type; to client
code, this structure is opaque (there is no need to directly access
its fields). The filter is constructed by a call to \texttt{kalman\_create}
or \texttt{kalman\_create\_options}, which returns a pointer to \texttt{kalman\_t}.
The interface to the parallel smoothers is a little different and
will be explained later.

In general, the memory management principle of the interface (and
the internal implementation) is that client code is responsible for
freeing memory that was allocated by a call to any function whose
name includes the word \texttt{create}. Therefore, when client code
no longer needs a filter, it must call \texttt{kalman\_free} and pass
the pointer as an argument. 

The functionality of the filter is exposed through functions that
correspond to methods in the MATLAB and Java implementations. These
functions expect a pointer to \texttt{kalman\_t} as their first argument.
The functions are not overloaded because C does not support overloading.
Missing matrices and vectors (e.g., to \texttt{evolve} and \texttt{observe})
are represented by a \texttt{NULL} pointer and default step numbers
(to \texttt{forget} , \texttt{estimate}, and so on) by $-1$. Here
is the declaration the functions. 
\begin{lstlisting}
kalman_t*        kalman_create         ();
kalman_t*        kalman_create_options (kalman_options_t options);
void             kalman_free           (kalman_t* kalman);

void             kalman_evolve    (kalman_t* kalman, int32_t n_i,                                                      
                                   kalman_matrix_t* H_i, kalman_matrix_t* F_i, kalman_matrix_t* c_i,
                                   kalman_matrix_t* K_i, char K_i_type);
void             kalman_observe   (kalman_t* kalman,                                                               
                                   kalman_matrix_t* G_i, kalman_matrix_t* o_i,
                                   kalman_matrix_t* C_i, char C_i_type);

int64_t          kalman_earliest  (kalman_t* kalman);
int64_t          kalman_latest    (kalman_t* kalman);
void             kalman_forget    (kalman_t* kalman, int64_t i);
void             kalman_rollback  (kalman_t* kalman, int64_t i);

void             kalman_smooth    (kalman_t* kalman);

kalman_matrix_t* kalman_estimate        (kalman_t* kalman, int64_t i);
kalman_matrix_t* kalman_covariance      (kalman_t* kalman, int64_t i);
char             kalman_covariance_type (kalman_t* kalman, int64_t i);

kalman_matrix_t* kalman_perftest        (kalman_t* kalman, ...); // see later
\end{lstlisting}
Note that input covariance matrices are represented by a \texttt{kalman\_matrix\_t}
and a representation code (a single character). The output of \texttt{kalman\_covariance}
is a matrix $W$ such that $C=(W^{T}W)^{-1}$ or $C$ itself, where
$C$ is the covariance matrix of the output of \texttt{kalman\_estimate}
on the same step. The function \texttt{kalman\_covariance\_type} specifies
whether $C$ is represented by itself or by its inverse factor $W$.

A small set of helper functions allows client code to construct input
matrices in the required format, to set their elements, and to read
and use matrices returned by UltimateKalman. Here are the declarations
of some of them (the full set is declared in \texttt{matrix\_ops.h},
included automatically by \texttt{kalman.h}).
\begin{lstlisting}
kalman_matrix_t* matrix_create(int32_t rows, int32_t cols);
void             matrix_free(kalman_matrix_t* A);

void   matrix_set(kalman_matrix_t* A, int32_t i, int32_t j, double v);
double matrix_get(kalman_matrix_t* A, int32_t i, int32_t j);

int32_t matrix_rows(kalman_matrix_t* A);
int32_t matrix_cols(kalman_matrix_t* A);
...
\end{lstlisting}

Client code is responsible for freeing matrices returned by \texttt{kalman\_estimate}
and \texttt{kal\-man\_\-covariance} by calling \texttt{matrix\_free}
when they are no longer needed.

\subsection{Options}

The C takes an integer-type options argument that specifies which
algorithm to use, as well as parameters for these algorithms (currently
only one parameter is supported). Different options are ORed together.
The option values defined in \texttt{kalman.h} are:
\begin{itemize}
\item \texttt{KALMAN\_ALGORITHM\_ULTIMATE}, \texttt{KALMAN\_ALGORITHM\_CONVENTIONAL},
\texttt{KALMAN\_ALGORITHM\_ODDEVEN}, and \texttt{KALMAN\_ALGORITHM\_ASSOCIATIVE},
which specify which algorithm to use. Specify exactly one of these
bit values.
\item \texttt{KALMAN\_NO\_COVARIANCE}, which tells the UltimateKalman and
the Oddeven algorithms not to compute the covariance matrices of the
estimates.
\end{itemize}

\subsection{Direct Invocation of the Parallel Smoothers}

The two parallel smoothers can be invoked for testing by first supplying
the evolution and observation equations using a sequence of calls
to \texttt{kalman\_evolve} and \texttt{kalman\_observe} and then calling
\texttt{kalman\_smooth}, but this normally not appropriate for high-performance
parallel software, because the construction of the input to the smoother
is completely sequential.

Instead, the parallel smoothers should be invoked directly on an array
of equations,
\begin{lstlisting}
void kalman_smooth_oddeven(kalman_options_t         options, 
                          kalman_step_equations_t** equations, 
                          kalman_step_index_t       k); 
void kalman_smoother_associative(...); // same arguments
\end{lstlisting}
The first argument contains options, as in the call to \texttt{kalman\_create\_options}.
The second, \texttt{equations}, is an array of \texttt{k} pointers
to structures that each define an evolution equation and an observation
equation, defined in \texttt{kalman.h}:
\begin{lstlisting}
typedef struct kalman_step_equations_st {
  kalman_step_index_t step; // logical step number, start from 0
  int32_t dimension;

  kalman_matrix_t* H;
  kalman_matrix_t* F;
  kalman_matrix_t* c;
  kalman_matrix_t* K;
  char             K_type;

  kalman_matrix_t* G;
  kalman_matrix_t* o;
  kalman_matrix_t* C;
  char             C_type;

  kalman_matrix_t* state;
  kalman_matrix_t* covariance;
  char             covariance_type;
} kalman_step_equations_t;
\end{lstlisting}

Parallel codes should normally allocate two arrays of length \texttt{k},
an arrays of structures and an array of pointers to these structures,
and ideally fill their elements using a multi-threaded code. The array
of pointers should be filled with the addresses of the elements in
the array of structures. Each structure should be filled with the
matrices that define the evolution and observation equations of one
step; the semantics are the same as in calls to \texttt{kalman\_evolve}
and \texttt{kalman\_observe}. The \texttt{dimension} field specifies
the dimension of the state vector, and the \texttt{step} field is
a sequence number that should start from zero.

When the call to the smoother returns, the \texttt{state} fields contain
the smoothed state estimates and the \texttt{covariance} and \texttt{covariance\_type}
fields contain the covariance of the state, unless the \texttt{KALMAN\_NO\_COVARIANCE}
bit was set in \texttt{options}.

The parallel-programming environment that the library uses, TBB, allows
codes to control the number of operating-system threads that are used
in a given computation, and a parameter called the block size. The
first parameter controls how many physical cores are used. The second
controls the overhead of parallelism: in parallel for loops and similar
constructs, the environment performs blocks of iterations sequentially
to reduce overhead. Our experiments indicate that a value of 16 is
a good for the block size. Callers should specify these two value,
using the following two functions defined in \texttt{parallel.h},
before calling a parallel smoother:
\begin{lstlisting}
void parallel_set_thread_limit(int p); 
void parallel_set_blocksize   (int b); 
\end{lstlisting}


\subsection{Building and Running the C Outside Matlab}

To help you integrate UltimateKalman into your own native code in
C or C++, the software includes three example programs that call
UltimateKalman and Windows and Linux/MacOS scripts that build executable
versions of the three programs. The scripts compile one of the programs
along with UltimateKalman, link it with BLAS and LAPACK libraries,
and run it. You should be able to use these scripts as examples of
how to compile and link UltimateKalman. 

These C programs, the C implementation of UltimateKalman, and the
build scripts are all under the \texttt{c} directory of the distribution
archive.

The three sample programs are \texttt{rotation.c}, a C implementation
of one of the example MATLAB programs, \texttt{performance.c}, a
program designed to measure the running time of UltimateKalman, and
\texttt{blastest.c}, a small program intended only to test the interface
to the BLAS and LAPACK libraries. The program \texttt{rotation.c}
performs the same computation that the expression \texttt{rotation(KalmanUltimate,5,2)}
performs in MATLAB and should output the same numerical results,
just like \texttt{Rotation.java}. The program \texttt{performance.c}
implements a Kalman smoother on problems with $n_{i}=m_{i}=6$ or
$n_{i}=m_{i}=48$ using orthonormal matrices for $F_{i}$ and $G_{i}$
and with $H_{i}=I$. It measures and reports the running time of the
smoother.

If you invoke the build script, \texttt{build.bat} or \texttt{build.sh},
with no arguments, it build and runs \texttt{rotation.c}. To build
and run one of the other programs, invoke the script with the argument
\texttt{blastest} or \texttt{performance}.

The Windows script, \texttt{build.bat}, uses the Microsoft C command-line
compiler (\texttt{cl}) that comes with Microsoft's Visual Studio Community
2022~\cite{VSCommunity}, a free integrated development environment,
and the BLAS and LAPACK libraries that are part of Intel's free
oneAPI Math Kernel Library (MKL)~\cite{MKL}. Here is what you should
expect to see on the console when you build and run \texttt{blastest}
(ellipsis stand for deleted output that is not particularly interesting;
the output of the \texttt{blastest} program is shown in bold):
\begin{lstlisting}
C:\Users\stoledo\github\ultimate-kalman\c>build.bat blastest
...
**********************************************************************
** Visual Studio 2022 Developer Command Prompt v17.9.2
** Copyright (c) 2022 Microsoft Corporation
**********************************************************************
[vcvarsall.bat] Environment initialized for: 'x64'
:: initializing oneAPI environment...
   Initializing Visual Studio command-line environment...
   Visual Studio version 17.9.2 environment configured.
   "C:\Program Files\Microsoft Visual Studio\2022\Community\"
:  compiler -- latest
:  mkl -- latest
:  tbb -- latest
:: oneAPI environment initialized ::
generating test program blastest.exe
ultimatekalman.c
ultimatekalman.c(39): warning C4005: 'blas_int_t': macro redefinition
ultimatekalman.c(28): note: see previous definition of 'blas_int_t'
blastest.c
Generating Code...
generated test program
~BLAS test starting~
~A = matrix_print 2 3~
~1 2 3~
~4 5 6~
~B = matrix_print 3 2~
~7 8~
~9 10~
~12 13~
~C = matrix_print 2 2~
~125 137~
~293 323~
~Result should be:~
~  125  137~
~  293  323~
~BLAS test done~
done running test
build script done
\end{lstlisting}

When you run the Windows executable program yourself, make sure that
the directory where the MKL dynamically-linked libraries (\texttt{dll}
files) are stored is on your \texttt{path}. The same is true, of course,
for your own programs that use UltimateKalman. The installation of
MKL does not modify the path to include this library, but it does
provide a script that modifies the search path appropriately. In the
version of MKL that I used, this script is \texttt{c:\textbackslash Program
Files (x86)\textbackslash Intel\textbackslash oneAPI\textbackslash setvars.bat}. 

Under Linux, \texttt{build.sh} uses the BLAS and LAPACK libraries
that are installed in the Ubuntu Linux distribution using the commands
\begin{lstlisting}
sudo apt install libblas-dev
sudo apt install liblapack-dev
\end{lstlisting}
These software packages install the libraries in a directory that
is already on the search path, so no special configuration of the
search path is required. These particular implementations of the BLAS
and LAPACK are not high-performance implementations, but since UltimateKalman
typically handles fairly small matrices, a high-performance library
like Intel's MKL may not provide performance benefits. However, MKL
is also available for Linux and you can certainly use it.

To successfully link UltimateKalman with other implementations of
the BLAS and LAPACK, you may need to set some preprocessor variables
that control how UltimateKalman calls these libraries. Most of the
variations are due to the fact that these libraries were originally
implemented in Fortran. The preprocessor variables that control the
behavior of UltimateKalman are listed and explained in Table~\ref{tab:C-pre-variables}.

\begin{table}
\begin{centering}
\begin{tabular}{ll>{\raggedright}p{0.4\textwidth}}
\hline 
variable name & requires a value? & explanation\tabularnewline
\hline 
\texttt{BUILD\_MKL} & no & specifies that MKL is used; sets all the other BLAS and LAPACK
variables (so you do not need to)\tabularnewline
\texttt{BUILD\_BLAS\_INT} & yes & C data type that specifies a row or column index or a dimension of
a matrix; usually either \texttt{int32\_t} or \texttt{int64\_t}\tabularnewline
\texttt{HAS\_BLAS\_H} & no & specifies that the \texttt{blas.h} header is available\tabularnewline
\texttt{HAS\_LAPACK\_H} & no & specifies that the \texttt{lapack.h} header is available\tabularnewline
\texttt{BUILD\_BLAS\_UNDERSCORE} & no & add an underscore to names of BLAS and LAPACK functions\tabularnewline
\texttt{BUILD\_BLAS\_STRLEN\_END} & no & add string-length arguments to calls to the BLAS and LAPACK\tabularnewline
\texttt{BUILD\_DEBUG\_PRINTOUTS} & no & generates run-time debug printouts\tabularnewline
\texttt{NDEBUG} & no & suppresses run-time assertion checking\tabularnewline
\texttt{BUILD\_WIN32\_GETTIMEOFDAY} & no & required under Windows; do not use under Linux or MacOS\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:C-pre-variables}Preprocessor variables that control how
UltimateKalman calls the BLAS and LAPACK, as well as several other
aspects of its behavior.}
\end{table}


\section{\label{sec:testing-and-examples}Code Examples }

The software distribution of UltimateKalman includes five MATLAB
example functions, stored in the \texttt{examples} sub-directory,
that demonstrate how to use the library:
\begin{itemize}
\item \texttt{rotation.m}, modeling a rotating point in the plane (this
example is also implemented in C and Java, as described above).
\item \texttt{constant.m}, modeling an fixed scalar or a scalar that increases
linearly with time, and with observation covariance matrices that
are identical in all steps except perhaps for one exceptional step.
\item \texttt{add\_remove.m}, demonstrating how to use $H_{i}$ to add or
remove parameters from a dynamic system.
\item \texttt{projectile.m}, implementing the model and filter of a projectile
described by Humpherys et al.~\cite{AFreshLook2012}.
\item \texttt{clock\_offsets.m}, implementing clock-offset estimation in
a distributed sensor system. This example demonstrates how to handle
parameters that appear only in one step.
\end{itemize}
The mathematical details of these models are described in the article
that describes UltimateKalman. 

The script \texttt{replication.m}, also in the \texttt{examples} sub-directory,
runs all of these examples and optionally generates the figures shown
in Section~5 of the article on UltimateKalman. Comparing the generated
figures to those in the article provides visual evidence that the
code runs correctly. The script can run not only the MATLAB implementation,
but also the C and Java implementations. This script assumes that
the corresponding libraries have already been built. The version of
the C library that MATLAB uses is built using the \texttt{UltimateKalman\_build\_\LyXZeroWidthSpace mex.m}
script, as explained in Section~\ref{sec:c-lang} above. The Java
version should be built outside MATLAB, as explained in Section~\ref{sec:java}.

\section{\label{sec:performance-testing}Support for Performance Testing}

All the implementations include a method, called \texttt{perftest},
designed for testing the performance of the filter. This method accepts
as arguments all the matrices and vectors that are part of the evolution
and observation equations, a step count, and an integer $d$ that
tells the method how often to take a wall-clock timestamp. The method
assumes that the filter has not been used yet and executes the filter
for the given number of steps. In each step, the state is evolved
and observed, the state estimate is requested, and the previous step
(if there was one) is forgotten. The same fixed matrices and vectors
are used in all steps.

This method allows us to measure the performance of all the implementations
without the overheads associated with calling C or Java from MATLAB.
That is, the C functions are called in a loop from C, the Java
methods are called from Java, and the MATLAB methods from MATLAB.

The method takes a timestamp every $d$ steps and returns a vector
with the average wall-clock running time per step in each nonoverlapping
group of $d$ steps.

\section{\label{sec:step-data-structure}Data Structures for the Step Sequence}

The information in this section helps to understand the implementations,
but is essentially irrelevant to users of UltimateKalman.

The Java implementation uses an \texttt{ArrayList} data structure
to represent the sequence of steps that have not been forgotten or
rolled back, along with an integer that specifies the step number
of the first step in the \texttt{ArrayList}. The data structure allows
UltimateKalman to add steps, to trim the sequence from both sides,
and to access a particular step, all in constant time or amortized
constant time.

The C implementation uses a specialized data structure with similar
capabilities. This data structure, called in the code \texttt{farray\_t},
is part of UltimateKalman. The sequence is stored in an array. When
necessary, the size of the array is doubled. The active part of the
array is not necessarily in the beginning, if steps have been forgotten.
When a step is added and there is no room at the end of the physical
array, then either the array is reallocated at double its current
size, or the active part is shifted to the beginning. This allows
the data structure to support appending, trimming from both sides,
and direct access to a step with a given index, again in constant
or amortized constant time.

The Java implementation stores the steps in a cell array. The implementation
is simple, but not as efficient as the data structure that is used
by the C version.

\bibliographystyle{plainurl}
\bibliography{kalman}

\end{document}
